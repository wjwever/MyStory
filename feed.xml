<?xml version='1.0' encoding='UTF-8'?>
<feed xmlns="http://www.w3.org/2005/Atom"><id>https://github.com/wjwever/gitblog</id><title>RSS feed of wjwever's gitblog</title><updated>2023-07-02T04:48:31.535229+00:00</updated><author><name>wjwever</name><email>1216451203@qq.com</email></author><link href="https://github.com/wjwever/gitblog"/><link href="https://raw.githubusercontent.com/wjwever/gitblog/master/feed.xml" rel="self"/><generator uri="https://lkiesow.github.io/python-feedgen" version="0.9.0">python-feedgen</generator><entry><id>https://github.com/wjwever/gitblog/issues/46</id><title>一些杂想</title><updated>2023-07-02T04:48:31.910283+00:00</updated><content type="html"><![CDATA[<p>最近突然感觉干的好累，</p>
<ul>
<li>5升6今年失败了，估计明年也升不了，涨工资无望</li>
<li>解码引擎的代码乱的跟一锅粥一样，干的心累，工作内容太杂了，平常写代码也少了，工作能力提升有限</li>
<li>产品团队现在走了一波，现在的技术PM都是外包的，理解业务的能力太弱了，，目前扮演的角色基本就是研发和业务的传话筒，导致整个项目规划的很乱。
马云说，员工想离职，主要有两个原因，一个是钱没给够，一个是心里委屈了。我现在的工作是钱少心里委屈，感觉是时候换一份工作了。</li>
</ul>
]]></content><link href="https://github.com/wjwever/gitblog/issues/46" rel="alternate"/><category term="生活笔记"/><published>2023-07-02T02:58:51+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/45</id><title>add_sos_eos</title><updated>2023-07-02T04:48:32.075279+00:00</updated><content type="html"><![CDATA[<pre><code class="language-python">def add_sos_eos(ys_pad: torch.Tensor, sos: int, eos: int,
                ignore_id: int) -&gt; Tuple[torch.Tensor, torch.Tensor]:
    &quot;&quot;&quot;Add &lt;sos&gt; and &lt;eos&gt; labels.

    Args:
        ys_pad (torch.Tensor): batch of padded target sequences (B, Lmax)
        sos (int): index of &lt;sos&gt;
        eos (int): index of &lt;eeos&gt;
        ignore_id (int): index of padding

    Returns:
        ys_in (torch.Tensor) : (B, Lmax + 1)
        ys_out (torch.Tensor) : (B, Lmax + 1)

    Examples:
        &gt;&gt;&gt; sos_id = 10
        &gt;&gt;&gt; eos_id = 11
        &gt;&gt;&gt; ignore_id = -1
        &gt;&gt;&gt; ys_pad
        tensor([[ 1,  2,  3,  4,  5],
                [ 4,  5,  6, -1, -1],
                [ 7,  8,  9, -1, -1]], dtype=torch.int32)
        &gt;&gt;&gt; ys_in,ys_out=add_sos_eos(ys_pad, sos_id , eos_id, ignore_id)
        &gt;&gt;&gt; ys_in
        tensor([[10,  1,  2,  3,  4,  5],
                [10,  4,  5,  6, 11, 11],
                [10,  7,  8,  9, 11, 11]])
        &gt;&gt;&gt; ys_out
        tensor([[ 1,  2,  3,  4,  5, 11],
                [ 4,  5,  6, 11, -1, -1],
                [ 7,  8,  9, 11, -1, -1]])
    &quot;&quot;&quot;
</code></pre>
<p>ys_in是添加了sos，尾部采用eos进行对齐
ys_out是添加了eos，</p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/45" rel="alternate"/><category term="wenet"/><published>2023-07-01T10:27:45+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/44</id><title>layer norm层</title><updated>2023-07-02T04:48:32.229070+00:00</updated><content type="html"><![CDATA[<p>xx</p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/44" rel="alternate"/><category term="wenet"/><published>2023-06-22T10:49:56+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/43</id><title>计算均值方差</title><updated>2023-07-02T04:48:32.372834+00:00</updated><content type="html"><![CDATA[<p>compute cmnv
代码在tools/compute_cmvn_stat.py中，核心代码如下：</p>
<pre><code class="language-python">            waveform = waveform * (1 &lt;&lt; 15)
            if self.resample_rate != 0 and self.resample_rate != sample_rate:
                resample_rate = self.resample_rate
                waveform = torchaudio.transforms.Resample(
                    orig_freq=sample_rate, new_freq=resample_rate)(waveform)

            mat = kaldi.fbank(waveform,
                              num_mel_bins=self.feat_dim,
                              dither=0.0,
                              energy_floor=0.0,
                              sample_frequency=resample_rate)
            mean_stat += torch.sum(mat, axis=0)
            var_stat += torch.sum(torch.square(mat), axis=0)
            number += mat.shape[0]
        return number, mean_stat, var_stat
</code></pre>
<p>examples/aishell/s0/run.sh里面计算均值方差的步骤：</p>
<pre><code class="language-bash">tools/compute_cmvn_stats.py --num_workers 16 --train_config $train_config \
    --in_scp data/${train_set}/wav.scp \
    --out_cmvn data/$train_set/global_cmvn

</code></pre>
]]></content><link href="https://github.com/wjwever/gitblog/issues/43" rel="alternate"/><category term="wenet"/><published>2023-06-18T13:25:35+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/42</id><title>降采样模块Conv2dSubsampling4</title><updated>2023-07-02T04:48:32.528651+00:00</updated><content type="html"><![CDATA[<h2>模型结构</h2>
<pre><code class="language-python">  (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
</code></pre>
<p>主要构造为一下三层</p>
<ul>
<li>conv 卷积层</li>
<li>out 线性层</li>
<li>pos_enc 位置编码层</li>
</ul>
<h2>代码分析</h2>
<pre><code class="language-python">x = x.unsqueeze(1)  # (b, c=1, t, f)
print(&quot;x.shape before conv&quot;, x.shape)
x = self.conv(x)
print(&quot;x.shape after conv&quot;, x.shape)
b, c, t, f = x.size()
x = self.out(x.transpose(1, 2).contiguous().view(b, t, c * f))
x, pos_emb = self.pos_enc(x, offset)
print(&#x27;x.shape after pos_enc, pos_emb.shape&#x27;, x.shape, pos_emb.shape)

print(&#x27;x_mask.shape&#x27;, x_mask.shape, x_mask[:,:,2::2][:,:,2::2].shape)
return x, pos_emb, x_mask[:, :, 2::2][:, :, 2::2]
</code></pre>
<p>在代码中加了三行print，观察tensor的形状:</p>
<pre><code class="language-python">x.shape before conv torch.Size([12, 1, 397, 80])
x.shape after conv torch.Size([12, 256, 98, 19])
x.shape after pos_enc, pos_emb.shape torch.Size([12, 98, 256]) torch.Size([1, 98, 256])
x_mask.shape torch.Size([12, 1, 397]) torch.Size([12, 1, 98])
</code></pre>
<ul>
<li>x送入卷积层的特征x的形状为(12, 1, 397, 80)，12表示batch，1为输入channel数，这个为了配置卷积层使用的，397表示时间维度frame的数量，80表示频率维度</li>
<li>x卷积完后形状为(12, 256, 98, 19)，12表示batch，256输出通道数，98 时间维度，19 频率维度</li>
<li>x 形状变换为（12， 98， 256 * 19），在进行线性变换为 （1298, 256）</li>
<li>x 位置编码，shape为 (12, 98, 256)， pos_emb 形状为 = [1, 98, 256 ]</li>
<li>mask 在时间T维度，做两次采样，为（12， 1，98）</li>
</ul>
]]></content><link href="https://github.com/wjwever/gitblog/issues/42" rel="alternate"/><category term="wenet"/><published>2023-06-18T11:46:23+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/41</id><title>wenet transformer 模型</title><updated>2023-07-02T04:48:32.685435+00:00</updated><content type="html"><![CDATA[<pre><code class="language-python">ASRModel(
  (encoder): TransformerEncoder(
    (embed): Conv2dSubsampling4(
      (conv): Sequential(
        (0): Conv2d(1, 256, kernel_size=(3, 3), stride=(2, 2))
        (1): ReLU()
        (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2))
        (3): ReLU()
      )
      (out): Sequential(
        (0): Linear(in_features=4864, out_features=256, bias=True)
      )
      (pos_enc): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (encoders): ModuleList(
      (0-11): 12 x TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (decoder): TransformerDecoder(
    (embed): Sequential(
      (0): Embedding(57, 256)
      (1): PositionalEncoding(
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
    (after_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
    (output_layer): Linear(in_features=256, out_features=57, bias=True)
    (decoders): ModuleList(
      (0-5): 6 x DecoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (src_attn): MultiHeadedAttention(
          (linear_q): Linear(in_features=256, out_features=256, bias=True)
          (linear_k): Linear(in_features=256, out_features=256, bias=True)
          (linear_v): Linear(in_features=256, out_features=256, bias=True)
          (linear_out): Linear(in_features=256, out_features=256, bias=True)
          (dropout): Dropout(p=0.0, inplace=False)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=256, out_features=2048, bias=True)
          (activation): ReLU()
          (dropout): Dropout(p=0.1, inplace=False)
          (w_2): Linear(in_features=2048, out_features=256, bias=True)
        )
        (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (norm3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)
        (dropout): Dropout(p=0.1, inplace=False)
      )
    )
  )
  (ctc): CTC(
    (ctc_lo): Linear(in_features=256, out_features=57, bias=True)
    (ctc_loss): CTCLoss()
  )
  (criterion_att): LabelSmoothingLoss(
    (criterion): KLDivLoss()
  )
)
</code></pre>
<p>上面是wenet的transformer网络结构，观察到可以发现有几个重要组成部分，后面会仔细研究这几个层的作用</p>
<ul>
<li>(embed): Conv2dSubsampling4  这是一个由2个卷积层加一个位置编码成构成</li>
<li>12 x encoder，12层transformer encoder层</li>
<li>6 x decoder，6层的transformer decoder层</li>
<li>loss层，CTC loss + LabelSmoothingLoss</li>
</ul>
<h2>Conv2dSubsampling4 模块</h2>
<pre><code class="language-python">x = x.unsqueeze(1)  # (b, c=1, t, f)
print(&quot;x.shape before conv&quot;, x.shape)
x = self.conv(x)
print(&quot;x.shape after conv&quot;, x.shape)
b, c, t, f = x.size()
x = self.out(x.transpose(1, 2).contiguous().view(b, t, c * f))
x, pos_emb = self.pos_enc(x, offset)
print(&#x27;x.shape after pos_enc, pos_emb.shape&#x27;, x.shape, pos_emb.shape)

print(&#x27;x_mask.shape&#x27;, x_mask.shape, x_mask[:,:,2::2][:,:,2::2].shape)
return x, pos_emb, x_mask[:, :, 2::2][:, :, 2::2]
</code></pre>
<p>在代码中加了三行print，观察tensor的形状:</p>
<pre><code class="language-python">x.shape before conv torch.Size([12, 1, 397, 80])
x.shape after conv torch.Size([12, 256, 98, 19])
x.shape after pos_enc, pos_emb.shape torch.Size([12, 98, 256]) torch.Size([1, 98, 256])
x_mask.shape torch.Size([12, 1, 397]) torch.Size([12, 1, 98])
</code></pre>
<ul>
<li>x送入卷积层的特征x的形状为(12, 1, 397, 80)，12表示batch，1为输入channel数，这个为了配置卷积层使用的，397表示时间维度frame的数量，80表示频率维度</li>
<li>x卷积完后形状为(12, 256, 98, 19)，12表示batch，256输出通道数，98 时间维度，19 频率维度</li>
<li>x 形状变换为（12， 98， 256 * 19），在进行线性变换为 （1298, 256）</li>
<li>x 位置编码，shape为 (12, 98, 256)， pos_emb 形状为 = [1, 98, 256 ]</li>
<li>mask 在时间T维度，做两次采样，为（12， 1，98）</li>
</ul>
<h2>MultiHeadedAttention 模块</h2>
<p>堆了12层encoder模块</p>
<pre><code class="language-python">        self.encoders = torch.nn.ModuleList([
            TransformerEncoderLayer(
                output_size,
                MultiHeadedAttention(attention_heads, output_size,
                                     attention_dropout_rate),
                PositionwiseFeedForward(output_size, linear_units,
                                        dropout_rate), dropout_rate,
                normalize_before) for _ in range(num_blocks)
        ])
</code></pre>
<p>MultiHeadAttention  attention_heads = 4 , output_size  = 256，    attention_dropout_rate: 0.0
forward_qkv函数</p>
<pre><code class="language-python">        n_batch = query.size(0)
        q = self.linear_q(query).view(n_batch, -1, self.h, self.d_k)
        k = self.linear_k(key).view(n_batch, -1, self.h, self.d_k)
        v = self.linear_v(value).view(n_batch, -1, self.h, self.d_k)
        q = q.transpose(1, 2)  # (batch, head, time1, d_k)
        k = k.transpose(1, 2)  # (batch, head, time2, d_k)
        v = v.transpose(1, 2)  # (batch, head, time2, d_k)
</code></pre>
<p>query，key，value都是上面的x，shape为(12, 98, 256)，先进行了 256到256的线性变换，接下来做了一个最后一个维度256变成（4， 64）操作，x的shape变为（12，98,4,64）最后进行transpose操作 维度变为（12,4,98,64）</p>
<pre><code class="language-python">        if cache.size(0) &gt; 0:
            key_cache, value_cache = torch.split(
                cache, cache.size(-1) // 2, dim=-1)
            k = torch.cat([key_cache, k], dim=2)
            v = torch.cat([value_cache, v], dim=2)
        # NOTE(xcsong): We do cache slicing in encoder.forward_chunk, since it&#x27;s
        #   non-trivial to calculate `next_cache_start` here.
        new_cache = torch.cat((k, v), dim=-1)

        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)
        return self.forward_attention(v, scores, mask), new_cache
</code></pre>
<p>cache 相关逻辑暂时忽略，
scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)
这句计算q 和 k的相关系数，shape为 （12,4,98, 98）， self.d_k = 64
mask 保持不变 （12， 1， 98）</p>
<p>forward_attention函数</p>
<pre><code class="language-python">        n_batch = value.size(0)
        # NOTE(xcsong): When will `if mask.size(2) &gt; 0` be True?
        #   1. onnx(16/4) [WHY? Because we feed real cache &amp; real mask for the
        #           1st chunk to ease the onnx export.]
        #   2. pytorch training
        if mask.size(2) &gt; 0 :  # time2 &gt; 0
            mask = mask.unsqueeze(1).eq(0)  # (batch, 1, *, time2)
            # For last chunk, time2 might be larger than scores.size(-1)
            mask = mask[:, :, :, :scores.size(-1)]  # (batch, 1, *, time2)
            scores = scores.masked_fill(mask, -float(&#x27;inf&#x27;))
            attn = torch.softmax(scores, dim=-1).masked_fill(
                mask, 0.0)  # (batch, head, time1, time2)
        # NOTE(xcsong): When will `if mask.size(2) &gt; 0` be False?
        #   1. onnx(16/-1, -1/-1, 16/0)
        #   2. jit (16/-1, -1/-1, 16/0, 16/4)
        else:
            attn = torch.softmax(scores, dim=-1)  # (batch, head, time1, time2)
</code></pre>
<p>先计算一下batch的数量，12
判断mask.size(2) &gt; 0, 答案是true，进入if分支
mask变为（12,1,1,98），然后eq(0) 相当于取反操作
scores = scores.masked_fill(mask, -float('inf'))，score在mask为1的地方赋值为负无穷大
attn = torch.softmax(scores, dim=-1).masked_fill(mask, 0.0) ，scores最后一维取softmax，并把mask为1的地方赋值为0
attn shape应该还是（12,4,98,98），但是每个head都考虑了mask</p>
<pre><code class="language-python">        p_attn = self.dropout(attn)
        x = torch.matmul(p_attn, value)  # (batch, head, time1, d_k)
        x = (x.transpose(1, 2).contiguous().view(n_batch, -1,
                                                 self.h * self.d_k)
             )  # (batch, time1, d_model)

        return self.linear_out(x)  # (batch, time1, d_model)
</code></pre>
<p>attn进行dropout操作，
x = torch.matmul(p_attn, value)  # (batch, head, time1, d_k)  # p_attn = (12,4,98,98)  * value = (12, 4, 98, 64) ,   attention操作，shape为（12,4,98,64）
x 进行transpose操作 （12,98,4,64），再变换成（12,98,256），和送进去的shape一样，但是进行了attention操作
再做一个linear线性层变换，维度还是（12,98,256）</p>
<h2>self_attn 函数讲解</h2>
<p><a href="https://zhuanlan.zhihu.com/p/338817680">https://zhuanlan.zhihu.com/p/338817680</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/41" rel="alternate"/><category term="wenet"/><published>2023-06-18T09:18:05+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/40</id><title>wenet学习</title><updated>2023-07-02T04:48:32.844201+00:00</updated><content type="html"><![CDATA[<h2>大纲</h2>
<p><a href="https://github.com/wjwever/gitblog/issues/43">计算均值方差</a>
[batch 装填]
<a href="https://github.com/wjwever/gitblog/issues/41">transformer 模型结构</a>
<a href="https://github.com/wjwever/gitblog/issues/42">降采样模块Conv2dSubsampling4</a>
[encoder 结构]
[deocder 结构]
[loss 函数]
[ctc greedy search 解码算法]</p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/40" rel="alternate"/><category term="wenet"/><published>2023-06-17T13:57:19+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/39</id><title>代码生成工具</title><updated>2023-07-02T04:48:32.989619+00:00</updated><content type="html"><![CDATA[<p>codewisper，<a href="https://www.bilibili.com/video/BV1Ch4y1g7bb/?spm_id_from=333.1007.tianma.1-2-2.click&amp;vd_source=abfee16ef2590619e4f7f98a1dcab411">https://www.bilibili.com/video/BV1Ch4y1g7bb/?spm_id_from=333.1007.tianma.1-2-2.click&amp;vd_source=abfee16ef2590619e4f7f98a1dcab411</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/39" rel="alternate"/><category term="杂七杂八"/><published>2023-06-17T02:33:55+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/38</id><title>pytorch dataload学习</title><updated>2023-07-02T04:48:33.136231+00:00</updated><content type="html"><![CDATA[<p><a href="https://blog.csdn.net/weixin_35757704/article/details/118857863">https://blog.csdn.net/weixin_35757704/article/details/118857863</a>
<a href="https://blog.csdn.net/weixin_35757704/article/details/119241547">https://blog.csdn.net/weixin_35757704/article/details/119241547</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/38" rel="alternate"/><category term="杂七杂八"/><published>2023-06-16T07:39:58+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/37</id><title>c++ 类的静态函数提示找不到定义</title><updated>2023-07-02T04:48:33.284548+00:00</updated><content type="html"><![CDATA[<p>公司代码两个同名的类，位于不同的命名空间，编译的时候只能找到一个，死活找不到另一个，需要仔细研究一下
周末在家试了下，没有复现，比较奇怪，对命名空间这块确实不太熟悉，需要加强。
类A，有一个lower的静态函数</p>
<pre><code class="language-c++">#include &lt;string&gt;
#include &lt;algorithm&gt;
#include &lt;cctype&gt;

namespace easr {
namespace nnlm {
    class strops {
        public:
            static void lower(std::string &amp;str);
    };
}
</code></pre>
<p>类B，也有一个lower的静态函数
classB.h</p>
<pre><code class="language-c++">#include &lt;string&gt;
#include &lt;algorithm&gt;
#include &lt;cctype&gt;

namespace easr {
    class strops {
        public:
            static void lower(std::string &amp;str);
    };
} 
</code></pre>
<p>main函数里面尝试调用两个函数，也都成功了，后续还需继续研究下。</p>
<pre><code class="language-c++">#include &quot;classA.h&quot;
#include &quot;classB.h&quot;
#include &quot;iostream&quot;

int main() {
    std::string temp = &quot;HELLO&quot;;
    easr::nnlm::strops::lower(temp);  
    easr::strops::lower(temp);  
    return 0;
}

</code></pre>
<p>代码：<a href="https://github.com/wjwever/cpp-extensions/tree/master/issue%2337">https://github.com/wjwever/cpp-extensions/tree/master/issue%2337</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/37" rel="alternate"/><category term="c++开发"/><published>2023-06-16T03:23:31+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/36</id><title>c++ 符号暴露问题</title><updated>2023-07-02T04:48:33.430958+00:00</updated><content type="html"><![CDATA[<p>问题：
代码里有静态库libsta.a，还有一个动态库libdy.so，编译的时候动态库引用了静态库的A函数。后续更新动态库，使用A、B函数。这时候报错B函数找不到符号，需要仔细研究一下。</p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/36" rel="alternate"/><category term="c++开发"/><published>2023-06-16T03:21:33+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/35</id><title>c++ 编译系统BLADE</title><updated>2023-07-02T04:48:33.578180+00:00</updated><content type="html"><![CDATA[<h2>安装依赖</h2>
<p>blade的官方文档  <a href="https://github.com/chen3feng/blade-build/blob/master/doc/zh_CN/prerequisites.md">外部软件依赖</a>提到了安装的一些依赖:</p>
<blockquote>
<p>Blade 运行时需要以下依赖：</p>
<ul>
<li>Linux 或 Mac 操作系统</li>
<li>Python v2.7+</li>
<li>Ninja v1.8+
Blade还能和以下软件协作：</li>
<li>ccache v3.1+</li>
<li>distcc
Blade 编译项目时可能需要到：</li>
<li>gcc v4.0+</li>
<li>jdk v1.6+</li>
<li>scala v2.10+</li>
<li>swig   v2.0+ (required for swig_library)</li>
<li>flex v2.5+ (required for lex_yacc)</li>
<li>bison v2.1+ (required for lex_yacc)</li>
</ul>
</blockquote>
<p>系统我的是mac，python2.7已经预先安装好了，接下来就是安装Ninja就行了，用brew安装，实测可以安装成功</p>
<pre><code>brew install Ninja
</code></pre>
<h2>安装blade</h2>
<p>进入源代码目录，执行一下命令，blade工具会安装到~/bin目录下，接下来重新打开终端就可以使用了</p>
<pre><code>./install
</code></pre>
<h2>quick start</h2>
<pre><code>cd blade-build-master/example/quick-start
blade build :hello-world
</code></pre>
<p>执行以上命令就可以发现build64_release，这个目录了，这个可执行文件可以被执行</p>
<pre><code>➜  quick-start ./build64_release/hello-world
Hello, World!
</code></pre>
<h2>使用感受</h2>
<p>在百度一直使用bcloud(comake2)构建c++项目，十分方便。免去了手写Makefile的痛苦，很多项目都不需要从零开始，其中的一个配置类似如下：</p>
<pre><code>WORKROOT(&#x27;../../../&#x27;)
CopyUsingHardLink(True)
CPPFLAGS(&#x27;-D_GNU_SOURCE -D__STDC_LIMIT_MACROS -DVERSION=\\&quot;1.9.8.7\\&quot;&#x27;)
CFLAGS(&#x27;-g -pipe -W -Wall -fPIC&#x27;)
CXXFLAGS(&#x27;-g -pipe -W -Wall -fPIC&#x27;)
INCPATHS(&#x27;. ./include ./output ./output/include&#x27;)
CONFIGS(&#x27;lib2-64/dict@dict_3-1-15-0_PD_BL&#x27;)
CONFIGS(&#x27;lib2-64/ullib@ullib_3-1-41-0_PD_BL&#x27;)
CONFIGS(&#x27;public/configure@configure_1-2-1-0_PD_BL&#x27;)
CONFIGS(&#x27;public/ependingpool@ependingpool_1-0-6-0_PD_BL&#x27;)
Application(&#x27;test&#x27;,Sources(user_sources))
StaticLibrary(&#x27;test&#x27;,Sources(user_sources),HeaderFiles(user_headers))
SharedLibrary(&#x27;test&#x27;,Sources(user_sources),HeaderFiles(user_headers))
</code></pre>
<p>基本思路是：新的项目相当于代码树的叶子节点，它可以依赖现有代码树上有权限的任意的一个字节点代码。comake2生成Makefile文件进行编译。</p>
<p>WORKROOT： 指定了这颗代码树的根节点的相对位置
CONFIGS：指定了你要依赖的库的位置，以及具体的版本，如果不指定则依赖trunk的代码，这个和maven的snapshot版本等概念类似。
Application: 输出二进制可运行
StaticLibrary：输出静态库
SharedLibrary：输出动态库</p>
<p>很可惜bcloud 一直没有开源。
类似的工具在其他的语言已经有了很好的解决方案
nodejs － npm
php － composer
python － pip
java － maven
不过 blade效果也是很不错的，相比cmake，好用太多了，以后业务项目都用blade了。</p>
<h2>参考文档</h2>
<p><a href="https://github.com/chen3feng/blade-build/tree/master/doc/zh_CN">https://github.com/chen3feng/blade-build/tree/master/doc/zh_CN</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/35" rel="alternate"/><category term="c++开发"/><published>2023-06-13T08:16:54+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/34</id><title>c++ clock函数的坑</title><updated>2023-07-02T04:48:33.730678+00:00</updated><content type="html"><![CDATA[<p><img src="https://github.com/wjwever/gitblog/assets/50772316/3302a969-832b-4877-bddf-206eadebe681" alt="b0efac9e6230de62f23baf1636133b3b" />
<a href="https://blog.csdn.net/iLOVEJohnny/article/details/104602557">https://blog.csdn.net/iLOVEJohnny/article/details/104602557</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/34" rel="alternate"/><category term="c++开发"/><published>2023-06-13T06:24:22+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/33</id><title>C++ lambda表达式</title><updated>2023-07-02T04:48:33.878469+00:00</updated><content type="html"><![CDATA[<p>lambda表达式简单说就是一个匿名函数，如下是一个lambda表达式：</p>
<pre><code>    auto vec_to_string = [](const std::vector&lt;float&gt;&amp; vec) -&gt; std::string {
        speech::decoder::Simpleostringstream stream;
        stream &lt;&lt; &quot;[&quot;;
        for (int i = 0; i &lt; vec.size(); ++i) {
            if (i) {
                stream &lt;&lt; &quot;, &quot;;
            }
            stream &lt;&lt; vec[i];
        }
        stream &lt;&lt; &quot;]&quot;;
        return stream.str();
    };
</code></pre>
<p><img src="https://github.com/wjwever/gitblog/assets/50772316/ca29917f-5523-4445-bbd6-2b270a56fc65" alt="image" />
参考：<a href="https://blog.csdn.net/qq_37085158/article/details/124626913">https://blog.csdn.net/qq_37085158/article/details/124626913</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/33" rel="alternate"/><category term="c++开发"/><published>2023-06-13T05:29:58+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/32</id><title>c++编译过程阅读笔记</title><updated>2023-07-02T04:48:34.029108+00:00</updated><content type="html"><![CDATA[<h1>gcc/g++编译过程阅读笔记</h1>
<ol>
<li>
<p>预处理，生成.i的文件</p>
<pre><code class="language-c++">g++ -E main.cpp &gt; main.i 
</code></pre>
<p>预处理后不生成文件，因此需要重定向到一个文件中</p>
</li>
<li>
<p>将预处理后的文件转换成汇编语言，生成.s文件</p>
<pre><code class="language-c++">g++ -S main.cpp
</code></pre>
</li>
<li>
<p>汇编变为目标代码(机器代码)生成.o的文件</p>
<pre><code class="language-c++">g++ -c main.cpp 
</code></pre>
</li>
<li>
<p>连接目标代码,生成可执行程序</p>
<pre><code class="language-c++">g++ main.o -o main //生成的可执行程序名为main ，如果执行命令 　g++ main.o  这样默认生成a.out，也就是main与a.out是一个只是名字不同而已
</code></pre>
</li>
</ol>
<p>那么，是在哪里实现”cout”函数的呢？系统把这些函数实现都被做到名为stdc++的库文件中去了，在没有特别指定时，g++会到系统默认的搜索路径**”/usr/lib”**下进行查找，也就是链接到stdc++库函数中去，这样就能实现函数”cout”了，而这也就是链接的作用。</p>
<h1>gcc/g++之动态静态编译库函数</h1>
<p>将这几个文件编译成动态库libdynamic.so。编译命令如下：</p>
<pre><code>g++ dynamic_a.cpp dynamic_b.cpp dynamic_c.cpp -fPIC -shared -o libdynamic.so
</code></pre>
<h2>参数说明</h2>
<p>-shared：该选项指定生成动态连接库</p>
<p>-fPIC：表示编译为位置独立的代码，不用此选项的话编译后的代码是位置相关的所以动态载入时是通过代码拷贝的方式来满足不同进程的需要，而不能达到真正代码段共享的目的。</p>
<h3>将main.cpp与libdynamic.so链接成一个可执行文件main。命令如下：</h3>
<pre><code>g++ main.cpp -L. -ldynamic -o main
</code></pre>
<p>-L.：表示要连接的库在当前目录中</p>
<p>-ldynamic：编译器查找动态连接库时有隐含的命名规则，即在给出的名字前面加上lib，后面加上.so来确定库的名称</p>
<p>测试可执行程序main是否已经链接的动态库libdynamic.so，如果列出了libdynamic.so，那么就说明正常链接了。可以执行以下命令：</p>
<pre><code>ldd main
</code></pre>
]]></content><link href="https://github.com/wjwever/gitblog/issues/32" rel="alternate"/><category term="c++开发"/><published>2023-06-12T05:31:33+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/31</id><title>vim-surround插件</title><updated>2023-07-02T04:48:34.181349+00:00</updated><content type="html"><![CDATA[<h2>简介</h2>
<p>生命在于折腾，没事鼓捣一下vim，今天发现的一个杀手级插件是vim-surround，这个插件可以快速对一段文本加上扩号，引号等等，简直是编程大杀器。先来看看网有的评论吧：</p>
<blockquote>
<p><a href="https://github.com/tpope/vim-surround">&quot;vim-surround</a>，tpope大神的一款life-changed插件.&quot;
&quot;直到发现了大牛<a href="http://www.vim.org/account/profile.php?user_id=9012">Tim</a> Pope的<a href="https://github.com/tpope/vim-surround">surround</a>的插件，一切都迎刃而解了。（对的就是那个写了<a href="https://github.com/tpope/vim-pathogen">pathogen</a>的家伙，他一个人就贡献了30多个vim插件，仰视之）&quot;</p>
</blockquote>
<h2>安装</h2>
<blockquote>
<p>项目的地址是：<a href="https://github.com/tpope/vim-surround">https://github.com/tpope/vim-surround</a>
如果采用Vundle安装的话，就需要在vim配置文件中添加：
Plugin 'tpope/vim-surround'
再执行：PluginInstall 就好了。</p>
</blockquote>
<h2>使用</h2>
<p>这个插件功能还是十分强大的，目前我只了解了他的基本功能，不过根据28原则，这也应该够了，后续功能再慢慢补充～
首先在vimrc中对该插件进行配置如下：</p>
<pre><code>    vmap &quot; S&quot;
    vmap &#x27; S&#x27;
    vmap ` S`
    vmap [ S[
    vmap ( S(
    vmap { S{
    vmap } S}
    vmap ] S]
    vmap ) S)
    vmap &gt; S&gt;
</code></pre>
<p>比如下面代码我想快速在 iostream加上&lt;&gt;那么可以这样操作：</p>
<ul>
<li>ve 选中iostream这个单词</li>
<li>&gt;给iostream加上尖括号
<img src="https://github.com/wjwever/gitblog/assets/50772316/79891a7d-f463-4be3-aaa7-7fcecd37c64f" alt="image" /></li>
</ul>
]]></content><link href="https://github.com/wjwever/gitblog/issues/31" rel="alternate"/><category term="开发工具"/><published>2023-06-12T05:28:04+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/30</id><title>beam search</title><updated>2023-07-02T04:48:34.327025+00:00</updated><content type="html"><![CDATA[<p>学习beam search </p>
<p>基础：</p>
<p><a href="https://blog.csdn.net/guolindonggld/article/details/79938567">https://blog.csdn.net/guolindonggld/article/details/79938567</a></p>
<p>进阶：</p>
<p><a href="https://baijiahao.baidu.com/s?id=1676193446313598976&amp;wfr=spider&amp;for=pc">https://baijiahao.baidu.com/s?id=1676193446313598976&amp;wfr=spider&amp;for=pc</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/30" rel="alternate"/><category term="杂七杂八"/><published>2023-06-12T05:22:18+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/29</id><title>PCM数据格式</title><updated>2023-07-02T04:48:34.466528+00:00</updated><content type="html"><![CDATA[<p><a href="https://www.jianshu.com/p/e568f94cdf6a">https://www.jianshu.com/p/e568f94cdf6a</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/29" rel="alternate"/><category term="杂七杂八"/><published>2023-06-12T05:16:13+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/28</id><title>先验概率和后验概率</title><updated>2023-07-02T04:48:34.616250+00:00</updated><content type="html"><![CDATA[<blockquote>
<p>这两个概念一直搞得我很迷惑。这里用一个例子来区分一下。</p>
</blockquote>
<h2>先验概率</h2>
<p>事情还没有发生，根据以往的经验来判断事情发生的概率。是“由因求果”的体现。</p>
<blockquote>
<p>扔一个硬币，在扔之前就知道正面向上的概率为0.5。这是根据我们之前的经验得到的。这个0.5就是先验概率。</p>
</blockquote>
<h2>后验概率</h2>
<p>事情已经发生了，有多中原因，判断事情的发生是由哪一种原因引起的。是“由果求因”。</p>
<blockquote>
<p>今天上学迟到了，有两个原因，一个是自行车坏了，一个是生病了。后验概率就是根据结果（迟到）来计算原因（生病/自行车坏了）的概率。
数学表达上，后验概率和条件概率有相同的形式</p>
</blockquote>
<p><a href="https://www.jianshu.com/p/0aeae4d82daa">https://www.jianshu.com/p/0aeae4d82daa</a>
<a href="https://www.jianshu.com/p/0aeae4d82daa">https://www.jianshu.com/p/0aeae4d82daa</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/28" rel="alternate"/><category term="杂七杂八"/><published>2023-06-12T05:11:52+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/27</id><title>c++运算符优先级</title><updated>2023-07-02T04:48:34.767992+00:00</updated><content type="html"><![CDATA[<p><a href="https://en.cppreference.com/w/cpp/language/operator_precedence">https://en.cppreference.com/w/cpp/language/operator_precedence</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/27" rel="alternate"/><category term="c++开发"/><published>2023-06-12T05:07:23+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/26</id><title>shell scripts</title><updated>2023-07-02T04:48:34.911863+00:00</updated><content type="html"><![CDATA[<ul>
<li>统计itg超时数目</li>
</ul>
<pre><code>grep total_cost . -r | awk -F&#x27;total_cost:|us&#x27; &#x27;{if($2&gt;100000)print $2}&#x27;
</code></pre>
<hr />
<ul>
<li>统计itg平均耗时</li>
</ul>
<pre><code>grep total_cost . -r | awk -F&#x27;total_cost:|us&#x27;  &#x27;BEGIN{cnt=0;sum=0}{cnt+=1;sum+=$2}END{print sum/cnt}&#x27;
cat log/itg-server2.log* | grep total_cost | awk -F&#x27;total_cost:&#x27; &#x27;{print $2}&#x27;| awk -F&#x27; us&#x27; &#x27;BEGIN{sum=0} {if($1&gt;40000) sum+=1} END{print sum,NR, sum/NR}&#x27;
</code></pre>
<hr />
<ul>
<li>找出文件（filename）中包含123或者包含abc的行</li>
</ul>
<pre><code>grep -E &#x27;123|abc&#x27; filename // 找出文件（filename）中包含123或者包含abc的行
egrep &#x27;123|abc&#x27; filename // 用egrep同样可以实现
awk &#x27;/123|abc/&#x27; filename // awk 的实现方式2、与操作
</code></pre>
<hr />
<ul>
<li>从itg log中抽出itg输入</li>
</ul>
<pre><code>grep INPUT log  -r | awk -F &#x27;message:&#x27; &#x27;{print $2}&#x27;  | sed &#x27;s/.$//&#x27; &gt; train.input
</code></pre>
<hr />
<ul>
<li>sed 替换</li>
</ul>
<pre><code>sed -i &quot;s/9231/$port/g&quot; ./conf/$port.conf
</code></pre>
<hr />
<ul>
<li>sed替换某几行的内容</li>
</ul>
<pre><code>qqq
123
ppp
123
sed -i &#x27;2,5s#123#456#&#x27; aa.txt
sed &#x27;2,3s/123/456/&#x27; a.txt
这里跟上一个相比，没有加g，结果只是匹配到了开头的“\s”字符
说明g进行了一个全局的搜索
不带g的话，只是匹配每行的第一个字段，后面的不管
</code></pre>
<hr />
<ul>
<li>git 提交</li>
</ul>
<pre><code>git push origin HEAD:refs/for/wjw-xiaoduzaijia-sprint8.5
</code></pre>
<hr />
<ul>
<li>简单查看diff的文件</li>
</ul>
<pre><code>git diff --stat
</code></pre>
<hr />
<ul>
<li>在输出行中去除重复行</li>
</ul>
<pre><code>sort -u seq.txt
</code></pre>
<hr />
<ul>
<li>bash c 风格循环</li>
</ul>
<pre><code>ans=0
# 注意，这里的 for 循环要有两层括号。
for ((i=1;i&lt;=100;i++))
do
    let ans+=$i
done
echo $ans
</code></pre>
<hr />
<ul>
<li>查找文件text中第三行的内容</li>
</ul>
<pre><code> sed -n &#x27;3p&#x27; text
</code></pre>
<hr />
<ul>
<li>查找文件text中第二行到第四行的内容</li>
</ul>
<pre><code>sed -n &#x27;2,4p&#x27; text
</code></pre>
<hr />
<ul>
<li>删除空行</li>
</ul>
<pre><code>cat 文件名 |sed ‘/^$/d&#x27;
</code></pre>
<hr />
<ul>
<li>找rank_word</li>
</ul>
<pre><code>grep OUTPUT . -r | awk -F &#x27;rank_result:|\\]\\[rewrite_result&#x27; &#x27;{print $2}&#x27; &gt; rank_word
</code></pre>
<h2><img src="https://github.com/wjwever/gitblog/assets/50772316/ce4eb80b-f980-4372-891b-b2dc00ea2812" alt="image" /></h2>
<ul>
<li>查看redhat版本
<code>cat /etc/redhat-release</code></li>
</ul>
<hr />
<ul>
<li>sort -k</li>
</ul>
<pre><code>banana:30:5.5 
apple:10:2.5 
pear:90:2.3 
orange:20:3.4
sort -n -k 2 -t : facebook.txt
</code></pre>
<hr />
<ul>
<li>awk删除文件最后一列
<code>awk  &#x27;{$NF=&quot;&quot;;print}&#x27; a.txt</code></li>
</ul>
<hr />
<ul>
<li>获取文件全路径名</li>
</ul>
<pre><code>方法一:
readlink -f  note.txt
/home/cuizhiliang344/note.txt
方法二:
python -c &#x27;import os; print(os.path.abspath(&quot;note.txt&quot;))&#x27;
方法三:
ls $PWD/note.txt
</code></pre>
<hr />
<ul>
<li>获取文件名:</li>
</ul>
<pre><code>basename /home/cuizhiliang344/note.txt
note.txt
</code></pre>
<hr />
<ul>
<li>获取目录:</li>
</ul>
<pre><code>dirname /home/cuizhiliang344/note.txt
/home/cuizhiliang344
</code></pre>
<hr />
<ul>
<li>python 打开文本骚操作
<code>top_intents = set([x.strip() for x in open(intent_file, &#x27;r&#x27;)])</code></li>
</ul>
<hr />
<p>*文本编码格式转换</p>
<pre><code>iconv -f gb18030 -t utf-8 file1.txt -o file2.txt
</code></pre>
<hr />
<ul>
<li>tcp socket
<img src="https://github.com/wjwever/gitblog/assets/50772316/be220a7a-58e1-41d3-803d-11babcf85cc5" alt="image" />
<img src="https://github.com/wjwever/gitblog/assets/50772316/ad2aac13-bda8-4c84-9704-da8be4e9556a" alt="image" /></li>
</ul>
<hr />
]]></content><link href="https://github.com/wjwever/gitblog/issues/26" rel="alternate"/><category term="杂七杂八"/><published>2023-06-12T03:59:25+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/25</id><title>Linux限速解压</title><updated>2023-07-02T04:48:35.071688+00:00</updated><content type="html"><![CDATA[<p>需要安装pv工具
cat test.sql.tar | pv -e -t -b -L 10M |tar -xf -
<a href="https://linux.cn/article-6734-1.html">https://linux.cn/article-6734-1.html</a>
<a href="https://loveyu.org/5693.html">https://loveyu.org/5693.html</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/25" rel="alternate"/><category term="杂七杂八"/><published>2023-06-12T03:21:29+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/24</id><title>c++如何释放vector的内存</title><updated>2023-07-02T04:48:35.217933+00:00</updated><content type="html"><![CDATA[<p>vector<T>().swap(x);</p>
<p><a href="https://zhuanlan.zhihu.com/p/338390842">https://zhuanlan.zhihu.com/p/338390842</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/24" rel="alternate"/><category term="c++开发"/><published>2023-06-12T03:09:09+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/23</id><title>git如何撤销</title><updated>2023-07-02T04:48:35.366049+00:00</updated><content type="html"><![CDATA[<ul>
<li>
<p>情况一：文件被修改了，但未执行git add操作（working tree内撤销）
git checkout fileName
git checkout .</p>
</li>
<li>
<p>文件执行了git add操作，但想撤销对其的修改（index内回滚）
#取消暂存
git reset HEAD fileName
#撤销修改
git checkout fileName</p>
</li>
<li>
<p>git add后的代码，想撤销
git reset HEAD .
git reset HEAD a.txt</p>
</li>
<li>
<p>已在本地进行了多次git commit操作，现在想撤销到其中某次Commit
git reset [--hard|soft|mixed|merge|keep] [commit|HEAD]</p>
</li>
</ul>
<p><a href="https://blog.csdn.net/ligang2585116/article/details/71094887">https://blog.csdn.net/ligang2585116/article/details/71094887</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/23" rel="alternate"/><category term="杂七杂八"/><published>2023-06-12T02:41:56+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/22</id><title>关于这个博客</title><updated>2023-07-02T04:48:35.513433+00:00</updated><content type="html"><![CDATA[<h1>关于这个博客来历</h1>
<p>最近想写点博客，把以前看过的一些东西记录记录起来，我对写博客平台的要求主要有</p>
<ul>
<li>简洁</li>
<li>完善的markdown支持</li>
</ul>
<p>后来陆陆续续的尝试了一些平台，用的比较好有知乎，简书。
但这两个平台有个共同的缺点就是，个性化推送太多了，特别容易分散注意力。
在知乎上搜索了一下，发现了 <a href="https://github.com/yihong0618/gitblog">https://github.com/yihong0618/gitblog</a> 这个项目，被他的简洁和纯粹所打动，所以就把他给拷贝过来了，使用了大约一个月，感觉用起来非常舒服，要给作者点赞！</p>
<h1>配置方法</h1>
<ul>
<li>前提：申请github key</li>
<li>clone这个代码仓</li>
<li>删除BACKUP目录下的所有文件，并提交</li>
<li>修改.github/workflows/generate_readme.yml，并提交</li>
</ul>
<img width="461" alt="image" src="https://github.com/wjwever/gitblog/assets/50772316/4072cfa5-516b-4e56-ac84-f2eb50b60cff">
<ul>
<li>token 配置</li>
</ul>
<hr />
<img width="1086" alt="image" src="https://github.com/wjwever/gitblog/assets/50772316/3cb4fad1-6ef2-4b1f-8b92-0b6ddb895e1f">
<hr />
<img width="1108" alt="image" src="https://github.com/wjwever/gitblog/assets/50772316/fd582e65-8b60-494b-b328-16977a683731">
<hr />
<img width="860" alt="image" src="https://github.com/wjwever/gitblog/assets/50772316/7018a5c7-22fc-4a96-8533-bceaac8dbed6">
<h1>使用方法</h1>
<p>进入代码仓库的issue界面，选择新建一个issue，就可以新建一个笔记了，还可以选择label，就是分类啦
<img width="1618" alt="image" src="https://github.com/wjwever/gitblog/assets/50772316/9d1c5185-f4c1-4b56-b2ad-bd90c32544ed"></p>
<h1>更新点</h1>
<ul>
<li>增加了BACKUP/main.log，记录main.py的执行过程</li>
<li>issue 支持新加一个标题，内容为空</li>
</ul>
]]></content><link href="https://github.com/wjwever/gitblog/issues/22" rel="alternate"/><category term="Top"/><published>2023-06-11T15:21:51+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/21</id><title>个人简历</title><updated>2023-07-02T04:48:35.669617+00:00</updated><content type="html"><![CDATA[<h1>王佳伟</h1>
<ul>
<li>性别：男</li>
<li>出生年月：1992/12 </li>
<li>手机：13161014851 </li>
<li>Email：<a href="mailto:1216451203@qq.com">1216451203@qq.com</a></li>
<li>QQ/微信号：13161014851</li>
</ul>
<hr />
<h1>个人信息</h1>
<ul>
<li>硕士/中科院电子学研究所 </li>
<li>工作年限：6年</li>
<li>个人工作兴趣：人工智能/EDA软件/高性能计算/智慧家居</li>
</ul>
<hr />
<h1>工作经历</h1>
<p>（工作经历按逆序排列，最新的在最前边，按公司做一级分组，公司内按二级分组）</p>
<h2>百度AIG语音技术部 （ 2019年11月 ~ 至今 ）</h2>
<h3>[1] 车载语音识别引擎开发</h3>
<p>我在此项目负责了哪些工作，分别在哪些地方做得出色/和别人不一样/成长快，这个项目中，我最困难的问题是什么，我采取了什么措施，最后结果如何。这个项目中，我最自豪的技术细节是什么，为什么，实施前和实施后的数据对比如何，同事和领导对此的反应如何。</p>
<ul>
<li>项目背景：</li>
<li>工作难点：</li>
<li>亮点收益：</li>
</ul>
<h3>[2] 置信度模型优化</h3>
<p>我在此项目负责了哪些工作，分别在哪些地方做得出色/和别人不一样/成长快，这个项目中，我最困难的问题是什么，我采取了什么措施，最后结果如何。这个项目中，我最自豪的技术细节是什么，为什么，实施前和实施后的数据对比如何，同事和领导对此的反应如何。</p>
<h3>[3] 置信度训练数据挖掘</h3>
<p>（每个公司写2~3个核心项目就好了，如果你有非常大量的项目，那么按分类进行合并，每一类选一个典型写出来。其他的一笔带过即可。）</p>
<h2>北京华大九天科技股份有限公司（ 2017年7月 ~ 2019年11月 ）</h2>
<h3>[1] 异形面板布局布线工具负责人</h3>
<p>我在此项目负责了哪些工作，分别在哪些地方做得出色/和别人不一样/成长快，这个项目中，我最困难的问题是什么，我采取了什么措施，最后结果如何。这个项目中，我最自豪的技术细节是什么，为什么，实施前和实施后的数据对比如何，同事和领导对此的反应如何。</p>
<h3>[2] 首届集成电路设计挑战赛企业命题人</h3>
<p>我在此项目负责了哪些工作，分别在哪些地方做得出色/和别人不一样/成长快，这个项目中，我最困难的问题是什么，我采取了什么措施，最后结果如何。这个项目中，我最自豪的技术细节是什么，为什么，实施前和实施后的数据对比如何，同事和领导对此的反应如何。</p>
<hr />
<h1>开源项目</h1>
<p>（对于程序员来讲，没有什么比Show me the code能有说服力了）</p>
<ul>
<li><a href="http://github.com/yourname/projectname">STU</a>：项目的简要说明，Star和Fork数多的可以注明</li>
<li><a href="http://github.com/yourname/projectname">WXYZ</a>：项目的简要说明，Star和Fork数多的可以注明</li>
</ul>
<h1>个人专利</h1>
<p>（挑选你写作或翻译的技术文章，好的文章可以从侧面证实你的表达和沟通能力，也帮助招聘方更了解你）</p>
<ul>
<li><a href="http://get.jobdeer.com/706.get">一个产品经理眼中的云计算：前生今世和未来</a></li>
<li><a href="http://get.jobdeer.com/343.get">来自HeroKu的HTTP API 设计指南(翻译文章)</a> （ <code>好的翻译文章可以侧证你对英文技术文档的阅读能力</code>）</li>
</ul>
<h1>技能清单</h1>
<p>（我一般主张将技能清单写入到工作经历里边去。不过很难完整，所以有这么一段也不错）</p>
<p>以下均为我熟练使用的技能</p>
<ul>
<li>Web开发：PHP/Hack/Node</li>
<li>Web框架：ThinkPHP/Yaf/Yii/Lavaral/LazyPHP</li>
<li>前端框架：Bootstrap/AngularJS/EmberJS/HTML5/Cocos2dJS/ionic</li>
<li>前端工具：Bower/Gulp/SaSS/LeSS/PhoneGap</li>
<li>数据库相关：MySQL/PgSQL/PDO/SQLite</li>
<li>版本管理、文档和自动化部署工具：Svn/Git/PHPDoc/Phing/Composer</li>
<li>单元测试：PHPUnit/SimpleTest/Qunit</li>
<li>云和开放平台：SAE/BAE/AWS/微博开放平台/微信应用开发</li>
</ul>
<h1>致谢</h1>
<h2>感谢您花时间阅读我的简历，期待能有机会和您共事。</h2>
<p>这分简历感谢：<a href="https://github.com/geekcompany/ResumeSample/blob/master/c.md">https://github.com/geekcompany/ResumeSample/blob/master/c.md</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/21" rel="alternate"/><category term="Top"/><published>2023-06-11T15:02:33+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/20</id><title>github 代码比较</title><updated>2023-07-02T04:48:35.827262+00:00</updated><content type="html"><![CDATA[<p>在百度用icode代码管理工具，网页有专门的代码比较入口，可以轻松的比较两个commit的不同，貌似github也有：
参考网页：<a href="https://www.null123.com/question/detail-2608798.html">https://www.null123.com/question/detail-2608798.html</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/20" rel="alternate"/><category term="杂七杂八"/><published>2023-06-11T14:28:47+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/19</id><title>开始使用vscode</title><updated>2023-07-02T04:48:35.960564+00:00</updated><content type="html"><![CDATA[<p>写代码快6年了，一直都是用vim，自己DIY配置，这个方式可能已经过时了。。。。
今天开始入坑vscode，享受一下各种丰富的插件带来的效率提升</p>
<p>体验感受：</p>
<ul>
<li>开箱即用，不用想vim需要做很多配置</li>
<li>插件丰富，比vim配置插件要简单很多</li>
<li>代码跳转功能，这个很棒</li>
<li>支持vim插件，对vim的重度使用者比较友好
<img width="2048" alt="image" src="https://github.com/wjwever/gitblog/assets/50772316/05f75762-1e6a-4911-844b-bc82a90140b3"></li>
</ul>
<p>下载太慢解决的方法：<a href="https://blog.csdn.net/weixin_46621570/article/details/128007351">https://blog.csdn.net/weixin_46621570/article/details/128007351</a>
安装：<a href="https://zhuanlan.zhihu.com/p/113222681">https://zhuanlan.zhihu.com/p/113222681</a>
插件：<a href="https://zhuanlan.zhihu.com/p/112016680">https://zhuanlan.zhihu.com/p/112016680</a>
<a href="https://blog.csdn.net/libusi001/article/details/124309613">https://blog.csdn.net/libusi001/article/details/124309613</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/19" rel="alternate"/><category term="开发工具"/><published>2023-06-10T09:36:55+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/18</id><title>Python 协程</title><updated>2023-07-02T04:48:36.101498+00:00</updated><content type="html"><![CDATA[<h2>上代码：</h2>
<pre><code class="language-python">!/usr/bin/env python3
# async.py

import asyncio

async def count():
    print(&quot;One&quot;)
    await asyncio.sleep(1)
    print(&quot;Two&quot;)

async def main():
    await asyncio.gather(count(), count(), count())

asyncio.run(main())
</code></pre>
<h2>执行结果</h2>
<pre><code class="language-python">$ python3 async.py
One
One
One
Two
Two
Two
</code></pre>
<h2>知识要点</h2>
<ul>
<li>aync 关键字定义一个异步执行函数，这个函数在执行中间可以挂起，交给其他的协程执行</li>
<li>await 表示进入一个耗时操作，此时可以把CPU让给其他协程</li>
<li>在 async 函数main的里面，asyncio.gather() 方法将多个异步任务（三个 count()）包装成一个新的异步任务，必须等到内部的多个异步任务都执行结束，这个新的异步任务才会结束</li>
</ul>
<hr />
<p>参考<br />
<a href="http://www.ruanyifeng.com/blog/2019/11/python-asyncio.html">http://www.ruanyifeng.com/blog/2019/11/python-asyncio.html</a>
<a href="https://cloud.tencent.com/developer/inventory/5723/article/1639528">https://cloud.tencent.com/developer/inventory/5723/article/1639528</a>
<a href="https://zhuanlan.zhihu.com/p/137057192">https://zhuanlan.zhihu.com/p/137057192</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/18" rel="alternate"/><category term="杂七杂八"/><published>2023-06-04T09:59:44+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/17</id><title>2023代办事项</title><updated>2023-07-02T04:48:36.268052+00:00</updated><content type="html"><![CDATA[<ul>
<li><input disabled="" type="checkbox"> 考驾照</li>
<li><input disabled="" type="checkbox"> cuda编程学习</li>
<li><input disabled="" type="checkbox"> 读书30本</li>
<li><input disabled="" type="checkbox"> wenet学习</li>
<li><input disabled="" type="checkbox"> vue学习</li>
<li><input disabled="" type="checkbox"> 字幕数据挖掘</li>
<li><input disabled="" type="checkbox"> paddle speech</li>
<li><input disabled="" type="checkbox"> paddle ocr</li>
</ul>
]]></content><link href="https://github.com/wjwever/gitblog/issues/17" rel="alternate"/><category term="Top"/><published>2023-06-01T08:24:04+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/16</id><title>《字节跳动：从0到1的秘密》</title><updated>2023-07-02T04:48:36.575270+00:00</updated><content type="html"><![CDATA[<ul>
<li>
<p>张一鸣在处理员工管理问题时素以态度温和著称。他若是不满员工的表现，会温和地讲道理，还会给予真诚的鼓励，他用这样的办法来解决问题，员工们称这种方法有其独特的魔力。包括梁汝波在内的许多人都说，张一鸣认为愤怒是一种无用的情绪，是一种精神上的懒惰。相反，他努力追求一种“介于轻度喜悦和轻度抑郁之间”的理想状态。</p>
</li>
<li>
<p>在为公司起名字时，张一鸣做出了一个另类的选择：同时起中英文名字。经过集思广益，团队想出了“ByteDance”这个名字，据说灵感来自史蒂夫·乔布斯的一句名言：“光有技术是不够的。技术只有与人文相结合，才会带来让我们心灵歌唱的结果。”“Byte”是计算机的信息单位字节，代表着技术的声音，“Dance”则代表了人文。他们根据英文名起了中文名，即字节跳动。将“字节跳动”直译成英文，则是Byte Bounce，之所以有所变化，是因为团队担心会被误认为是舞蹈培训机构。如果你觉得这个英文名字听起来有点奇怪，那中文名字听起来就更奇怪了。</p>
</li>
<li>
<p>“就像扎克伯格创办脸书网连接了人和人，特拉维斯·卡兰尼克创办优步连接了人和车，今日头条是让信息和人实现更广泛和高效率的匹配。”张一鸣后来这样描述这款新旗舰产品的愿景。团队开始带着开阔的视野，开发一个更有野心的应用程序，以聚合和组织来自互联网的许多内容。这是一款以大数据和机器学习能力为驱动力的应用程序，可以根据人们的个性化偏好为他们提供量身定制的信息源，而且无须人类管理员。</p>
</li>
</ul>
]]></content><link href="https://github.com/wjwever/gitblog/issues/16" rel="alternate"/><category term="读书笔记"/><published>2023-06-01T05:30:46+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/15</id><title>《选择》</title><updated>2023-07-02T04:48:36.733521+00:00</updated><content type="html"><![CDATA[<h2>渴望胜利 心得总结</h2>
<ul>
<li>
<p>确定优先级：人不能太贪心，不要同时做很多件事。只专注于最关键的几件事，才能一步步走向胜利。</p>
</li>
<li>
<p>易于上手：设定可行的小目标，并确保这些小目标加在一起可以做成更大的事情。以我的SAT（美国学业能力倾向测验）备考为例，每半天学习20个单词的目标似乎不难，但加在一起，2500个单词就很可观了。</p>
</li>
</ul>
<hr />
<h2>寻找定位 心得总结</h2>
<ul>
<li>
<p>建立差异性：沃顿商学院的每个学生都很优秀，我仅仅是350个学生中的一员，必须为自己找到定位，建立自己的差异性，才有可能脱颖而出。</p>
</li>
<li>
<p>自我定位：作为中国人，作为亚洲人，这是我与大部分沃顿商学院的同学不同的地方。我要利用自己的差异性，推动外界对于中国、亚洲的理解，在这个过程中找到自己独特的价值。人生就是一个不断寻找定位的过程。</p>
</li>
</ul>
<hr />
<h2>牛津岁月 心得总结</h2>
<ul>
<li>
<p>建构知识大厦：在开启职业道路之前，需要建构好自己的知识大厦。只有打好基础，未来职业发展的上限才能更高，否则难免趋于平庸。</p>
</li>
<li>
<p>理解世界是如何运作的：正是在牛津大学的这些年，使我的思维变得更加敏锐，也使我更加具备了宏观意识。最重要的是，它促使我理解了“世界是如何运作的”。在离开沃顿商学院的岁月里，我了解到这个世界除了投行、华尔街和阿尔法收益，还有很多别的东西。</p>
</li>
<li>
<p>思考比知识重要：在当今这个信息时代，通过谷歌和百度可以轻易找到各种知识，但是思考方式会一直“镶嵌”在个人的职业生涯之中。重视仪式感：生活、学习和工作中的仪式感，并不是所谓的“做作”，它会让我们更加容易进入状态。这是牛津大学的仪式感带给我的启发。</p>
</li>
</ul>
<hr />
<h2>麦肯锡反思 心得总结</h2>
<ul>
<li>
<p>管理老板：只有当你的老板没事干时，你才是成功的，因为你已经解决了老板的所有问题。反之，若你对项目的思考不够周全，就会被自己的老板指点，被“分派”工作，陷入被动，更别说想要发言权了。在这样的工作强度中，我却应付自如，丝毫不觉得疲惫。我认为，我的动力来自“把自己当作老板一样去工作”。我永远要领先一步，每个项目都要比老板思考得更加深刻，把老板能考虑到的问题全部考虑进去。在我还是初级项目经理的时候，我会思考我的老板是如何分析这个项目的。我需要让他感觉到，我比他想得更多，这样我才有发言权，对整个项目的进度更有掌控力。只有这样，我才可以自由安排自己的时间，充分施展我的想法，而非见招拆招、疲于奔命。</p>
</li>
<li>
<p>培养从底层视角出发的领导力：我在麦肯锡时，会不断提醒自己，自己也是从初级分析师做上来的，很多方案需要考虑到其他员工执行时的难度，不能好高骛远。只有这样，才能赢得团队成员的认同，他们会认为你是务实的，也愿意为你努力。
*充分重视利益相关者：团队是很庞大的，如果只把目光锁定在客户身上，你永远无法做出一个完美的方案。所以，我在麦肯锡参与每个项目时，都会列出所有的利益相关者，思考我的工作将会以怎样的方式影响他们，我如何执行才能发挥最大的影响力。</p>
</li>
<li>
<p>这里必须提到的一个原理，就是许多人并不陌生的“二八法则”，又名“二八定律”，即20%的工作会影响到80%的结果，我们如何找到发挥关键性作用的那20%才是关键。在整个利益相关者的网络中找到了最具影响力的人员，你就可以找到影响80%的结果的关键点。熟练掌握“二八法则”，会使你的工作效率至少提升100%。其实“二八法则”存在于我们生活、工作的方方面面。不管我们现在的差异有多大，我们所有人的最终归宿都是一样的——死亡，因此我们需要做的是，在这段有限的生命旅途中，用最少的资源获得最大的影响力。上帝给了你一手牌，不管你认为牌好还是牌差，你都要通过努力使这一手牌获得最好的结果。对我来说，做任何事情，都要想清楚，怎样选择、怎样做才能获得最大的影响力，否则只是在浪费有限的时间和生命。扬长避短：既然我的Excel（电子表格软件）制作技能很难赶上别人，那么我为何不把自己的时间和精力放在自己的长处上，把这些长处放大到足以被人识别？久而久之，我在大家的心目中就被定位为一个沟通和分析能力较强的人，形成了个人的差异化优势。</p>
</li>
<li>
<p>少动多想：在会议中频繁点头的都是最年轻、资历最浅的那个人。当你参加一场会议时，要从更高的高度看待这场会议，不要让自己进入一个年轻分析员的角色。同时，你要减少自己的肢体语言，少动多想，这样才会让你看起来更资深。放慢语速只是成熟的表现之一，停下来更能体现一个人的修养与沉淀。当你愿意停下来倾听别人的意见时，你就又进了一步。当然，你要注意自己倾听的姿态。你是否在大佬发言时频繁点头，仿佛这个动作可以迅速拉近你与发言人的水平。如果你这么做，那可就大错特错了。在会议中频繁点头的都是最年轻、资历最浅的那个人。当你参加一场会议时，要逐渐达到一种“他我”的状态，即从第三方或上帝视角看待这场会议，不要让自己进入一个年轻分析员的角色。同时，你要减少自己的肢体语言，少动多想，这样才会让你看起来更资深。当然，以上都是些表面的东西，在职场上真正说服别人、赢得尊重的还是自己的专业水平。无论参加任何会议，都要提前做好准备，让自己成为最懂的那个人。记住，运用知识说服别人才是真正的成熟，也是克服童颜困扰的最强大工具。</p>
</li>
<li>
<p>不是每个人都要成为射手：就像篮球队一样，不是每个人都要做迈克尔·乔丹，不同的人负责不同的位置就行。这个团队已经有一个很好的射手，那我应该做的，就是配合他完成投篮。各司其职，工作才能顺利开展。</p>
</li>
<li>
<p>麦肯锡通过四个维度评估员工：第一，人(People)，即团队成员对你的认可度；第二，知识(Knowledge)，指你在某个行业或领域是否专业；第三，客户(Client)，即项目客户对你的认可度；第四，办公室(Offi ce)，即你对整个办公室的影响力。</p>
</li>
</ul>
<hr />
<h2>诺亚尾声 心得总结</h2>
<ul>
<li>
<p>时刻评估自己的价值：人在一个组织中会经历各种变化，比如从磨合期、上升期到平稳期乃至平庸期。我在诺亚也经历了类似的变化。随着诺亚的各项工作日趋稳定，我开始问自己一些问题：我还能为公司创造什么价值？我还能在这里学到什么新东西？</p>
</li>
<li>
<p>岗位永远在变化：在不断变化的时空中，总有当下最匹配的人选，所以没有一个岗位是永远属于一个人的。虽然诺亚在2014年刚好需要我这样的人去做集团总裁，助其国际化、专业化，但是当诺亚进入落地执行阶段时，或许便需要更加接地气的人来接手。</p>
</li>
<li>
<p>“空降”总裁不好当：之所以建议集团总裁候选人最好是内部人士，是因为我充分意识到“空降”的难度。事实上，“空降”总裁的成功率非常小，因为团队对你根本没有认可度。我当时也算是“半空降”的，因为麦肯锡的关系，之前我已经跟管理层有很紧密的合作了，所以诺亚的十几位核心高管都认识我，我们之间也有一定的默契。而要从外面找一个完全“空降”的总裁，是很难的，所以我建议从内部提拔。</p>
</li>
<li>
<p>走出舒适区：诺亚和Two Sigma是处于两个极端的两家公司。诺亚是本土化、旨在推动与华人有关的业务执行的公司，Two Sigma则是具有国际化视野和能力、青睐分析方法和研究方法的公司。我很喜欢这种不同的极端，因为我的人生原则一直是，人要走出舒适区，面对自己越不熟悉的东西，能学到的东西可能越多。麦肯锡也告诉我们：你永远不会达到一个准备好的状态，因为你永远没有准备好，所以放手去做吧。</p>
</li>
</ul>
<hr />
<h2>职业生涯中的错误决定 心得总结</h2>
<ul>
<li>
<p>创业需要破釜沉舟：由于拥有沃顿商学院、牛津大学的教育背景，以及律师事务所的工作经历，创业对我来说并非背水一战，我并没有把它当作一个事业，没有孤注一掷。每当我创业遇到困难时，我总会想，没关系，回去当律师也很有前途。所以，一旦我遇到挫折，就会选择放弃。这可不是一个创业者应有的心态。</p>
</li>
<li>
<p>建立人际关系网络：从全球范围来看，最有用的人际关系网络可能有三种：高盛网络、麦肯锡网络和哈佛大学网络。不夸张地说，这三张人际关系网左右了世界上的许多事情，在这些网络中建立的人脉要比其他场合牢靠得多。这样的人际关系的建立很多时候是出于大家对“出身”的认同。在高盛、麦肯锡和哈佛大学的经历，胜过任何一种名片，构成了强大的背书与认同感。不过，即便没有这些顶级网络，其他组织的人脉也是有价值的，我们需要随时留意巩固人脉，未来必将有所收获。</p>
</li>
<li>
<p>打好你手中的牌：人生就像纸牌游戏，你无法改变手中的牌，你能做的是想方设法打好手中的牌。牌的好坏只是一个起点，关键在于如何打出手中的牌。所以我常思考，我手中有这么多资源、这么多张牌，我应该怎样打出去，才能实现这副牌的最大价值。</p>
</li>
</ul>
<hr />
<h2>职业生涯中的正确决定 心得总结</h2>
<ul>
<li>
<p>押注正确的人：人生有时就像一场赌博，我有幸押对了人，因此有了相对顺遂的职业生涯。找到“对”的贵人，其实是一门艺术。这绝不是简单地找能力强或职位高的人，而是找到一种双向关系——你“投注”他，他也愿意“给”你。 把握大趋势：看准发展大势并押注，在我看来极其重要。纵观我的整个职业生涯，我似乎一直在尝试把握行业的发展趋势。有句话叫“站到了风口，猪都能飞起来”，但关键是要找到合适的风口，之后才能事半功倍。 </p>
</li>
<li>
<p>不断走出舒适区：我的每一个选择都是在尝试不同的东西，尽量走出自己的舒适区。在我看来，人们一定要尝试一些自己并不擅长的东西。如果我们去做一些自己不太擅长的事情，我们肯定能不断学到新的东西，而非故步自封。 </p>
</li>
<li>
<p>让别人看到你的“可利用价值”：在个人职业生涯中，我还发展了很多不同类型的人脉，这些都是我在这二十几年中不断去“播种”的结果。如今职场人士所理解的“建设人脉”似乎很简单，就是多交朋友，但事实并非如此。事实上，你一定要不断锻炼自己，让其他人看到与你保持关系的必要性，说简单点，就是让他们看到你的“可利用价值”，比如你对于事情的看法、你处理事情的能力等。</p>
</li>
<li>
<p>其实，人生规划也好，职业生涯的规划也好，并没有一个正确与错误的明确定义。每个人都可能在自己的人生路上看到一些机会。关键在于，每个人如何真正发挥好拥有的资源，并激发自己的潜力。这就有点像玩扑克牌——手上拿到的是什么牌，又如何把这副牌打到最好？这一点很重要。每个人手上拿到的牌都不一样。无论拿到的是怎样的牌，都要尽量去打好，这也是人生有趣的地方。</p>
</li>
</ul>
]]></content><link href="https://github.com/wjwever/gitblog/issues/15" rel="alternate"/><category term="读书笔记"/><published>2023-06-01T05:17:34+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/13</id><title>ctags使用方法</title><updated>2023-07-02T04:48:36.894359+00:00</updated><content type="html"><![CDATA[<ul>
<li>在代码目录下生成ctags：</li>
</ul>
<pre><code class="language-bash">ctags -R   --languages=c++ --langmap=c++:+.inl -h +.inl --c++-kinds=+px --fields=+aiKSz --extra=+q   --exclude=platform_mgr/* --exclude=android-ndk-r11c/* --exclude=output/* -f ./tags
</code></pre>
<ul>
<li>vimrc指定tag位置</li>
</ul>
<pre><code class="language-bash">set tags=tags;/
</code></pre>
<ul>
<li>vimrc注释autochdir</li>
</ul>
<pre><code>&quot; set autochdir                   &quot; 自动切换工作目录为当前文件所在的目录
</code></pre>
<blockquote>
<p>参考：<a href="https://blog.csdn.net/sinat_30603081/article/details/111192247">https://blog.csdn.net/sinat_30603081/article/details/111192247</a></p>
</blockquote>
]]></content><link href="https://github.com/wjwever/gitblog/issues/13" rel="alternate"/><category term="开发工具"/><published>2023-05-29T14:37:00+00:00</published></entry><entry><id>https://github.com/wjwever/gitblog/issues/10</id><title>开始学习cuda</title><updated>2023-07-02T04:48:37.045546+00:00</updated><content type="html"><![CDATA[<p>学习资料
（1）《CUDA by example》
（2）<a href="https://github.com/tpn/cuda-by-example">https://github.com/tpn/cuda-by-example</a></p>
]]></content><link href="https://github.com/wjwever/gitblog/issues/10" rel="alternate"/><category term="cuda"/><published>2023-05-29T13:45:27+00:00</published></entry></feed>